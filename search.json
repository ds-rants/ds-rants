[
  {
    "objectID": "twitter.html",
    "href": "twitter.html",
    "title": "Surprise…",
    "section": "",
    "text": "You really should get off that stupid platform that promotes the absence of thinking in 280 characters.\nThere is nothing of value that can be said in such a short format, its only a slogan.\nAnd don’t get me started on the nazi in chief who uses that for political interference and insider trading.\nSeriously, do a favor for your brain."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I like data science but I hate unnecessary complexity, convoluted things and a despise projects made up to answer problems that are not even there.\nThis site will provide a collection of reflections on hopefully modern data science problems, the bloat surrounding them, and the sad fact that most of projects completely fail or just don’t bring any value whatsoever.\nSwearing will be abundant, people doing stupid things will be called stupid and more…\nThankfully, there is no amount of swearing that cannot be nicely illustrated by memes, so buckle up!\nAnd Enjoy!"
  },
  {
    "objectID": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html",
    "href": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html",
    "title": "Your Pandas Code Is Bad And You Should Feel Bad!",
    "section": "",
    "text": "That’s it! Three times! The third time is the charm, as they say!\nIt has been three times, THIS VERY WEEK, that I’ve been pulled into a meeting because someone had a performance problem with their pandas code. Each time it’s the same problem: some kind of genius decides to remove all safety belts, starts hacking and typing until their code regurgitates something. Then that person just hopefully and magically wishes that it will produce the expected outcome. Well, the outcome is me being called, and I’m deeply aggravated:\nIF YOU HAVE FOR LOOPS IN YOUR PANDAS CODE, YOU ARE WRONG!\nThere, I said it…"
  },
  {
    "objectID": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#the-not-so-good",
    "href": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#the-not-so-good",
    "title": "Your Pandas Code Is Bad And You Should Feel Bad!",
    "section": "The not-so-good",
    "text": "The not-so-good\nThe first time was a young data analyst who produced a notebook to perform some anomaly detection on curves. It was running slow even though it was running on a GCP machine that could probably crack half of the Internet passwords in an hour. The first rookie mistake was trying to plot about 500 examples of curves with about 5000 points per curve because the sampling rate is under a millisecond. I mean, plotly is a great library, no doubt about it, but that is a lot of things to print on your screen.\nThe machine breathes a sigh of relief…\nBut the signs of abuse were deeper. I will overlook the code blocks with a width on screen of 700 characters because everyone loves to scroll right and left (Please just run ruff on your notebooks). I will purposely ignore the function that does data pre-processing AND plotting, for now… But I cannot turn a blind eye to the double-nested for loop with print statements every 10ms and in-place modification of your gigantic dataframe that propels your machine into locked-in syndrome.\nAlright, nothing that can’t be fixed with a little bit of explanation and starting from the basics: down-sampling large data, method chaining in pandas, and no for loops, please."
  },
  {
    "objectID": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#the-bad",
    "href": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#the-bad",
    "title": "Your Pandas Code Is Bad And You Should Feel Bad!",
    "section": "The bad",
    "text": "The bad\nThe second time felt awfully similar. I got called for support by a senior contractor because their code on our MLOPS pipeline in Vertex AI had crashed, apparently due to an out-of-memory error. For those who don’t know, Vertex AI is a GCP service that allows you to run machine learning jobs, using Kubernetes under the hood, so basically you can scale up the machine running your job quite a bit. Any data scientist would think logically that the thing crashed during the training, but it was the prediction part that had crashed, AFTER RUNNING FOR TWO DAYS!\nWhat kind of unholy job are you guys running there? Ah, you’re running a PyTorch model to classify texts, great! Are you trying to classify the whole internet for it to take this long? What’s the size of your dataset? 20K text samples and the whole size is around a few 100s MB? Mother… I don’t know how you’re doing it, but you really managed to mess this one up. In the absolute worst case, this should run in a matter of hours, not days!\nAlright! Time to deep dive and see what ungodly horrors lie at the bottom of this…\nMy good sir, I thank you for creating functions, but yours are 50+ lines long, take 10 different arguments, and modify things in place… I hope you have tests for this (who am I kidding) … Anyway, where is your logic for the prediction? … Within a class with snake-case naming, not the worst thing I will see today, I am sure… Ah, this is the meat of all, the “predict” method… And…\nNO! GOD! NO! PLEASE! NO!\nYou sir, are guilty of the sin of abusing the for loop and pd.concat pattern. Don’t tell me you are redoing this for each line of your dataframe? Of course you are! Are you even aware that for each line you are basically writing a whole new dataframe, which according to you is several 100s MB, that contains just an extra prediction compared to the old one, then doing an in-place operation to replace the old one, and you are wondering why your code takes this long? You’re not even wondering because it did not occur to you that such a job running for several days was a horrible mistake. Oh, and by the way, do you know that you have a triple-nested for loop here in this sub-function of your method “predict”?\nYeah, this thing is going places."
  },
  {
    "objectID": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#there-is-nothing-sacred-anymore",
    "href": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#there-is-nothing-sacred-anymore",
    "title": "Your Pandas Code Is Bad And You Should Feel Bad!",
    "section": "There is nothing sacred anymore",
    "text": "There is nothing sacred anymore\nThe pinnacle of incompetence was definitely reached by a few members of a consulting firm, you know one of the BIG players that sell their meat “highly trained experts” for a modest 2000-4000 dollars a day. Same scenario, I get added to a meeting whose objective was to determine if the MLOPS pipeline we developed can accommodate scaling up the model they developed because currently their prediction is taking 3-4 hours and they have only implemented 1 of the 100 possible cases. Obviously, it will be very difficult to run the job for all cases within a day. Obviously, they are using the largest machine they can for their Vertex AI job. Obviously, they are trying to say that their “high-end” solution is in danger, although we paid a hefty price for it. Obviously, it’s about blame shifting. Sadly, for them, I already know that they are full of shit.\nThe first reason is that a few days ago, I had already heard of one of their “great” engineers reaching for help because his highly efficient unit tests were not working in the CI because he did a bunch of calls to Google Storage and BigQuery in them. Calling the database in unit tests, genius… But the second and most important reason why they are full of shit is my secret weapon. It is because our generic MLOPS pipeline does quite a bit between jobs but almost nothing within the job per se, just a little bit of I/O at the start and the end, everything else is just the logic implemented by the “customer” data scientist. In other words, if things go sideways during the job, then you sir, you are the problem! Sorry, I’m not sorry.\nLet’s speed up the next 25 minutes of the discussion:\nSo, let’s see the logs… Apparently, so you have about 100 configurations and for every one of them you’re spending many minutes in method X doing some pre-processing… let’s pull up the corresponding code… And…\nNO! GOD! NO! PLEASE! NO!\n\n1default_dict_of_df : dict[str, list[pd.DataFrame]] = ...\n\ndata_per_provider = {\"total\": [], **default_dict_of_df}\n\nfor provider in dataset[\"provider\"].unique():\n    provider_df = dataset[dataset[\"provider\"] == provider]\n\n    data_per_provider[\"total\"].append(\n2        generate_feature_time_series(\n            provider_df, date_index, provider\n        )\n    )\n    for feature in list_of_feature:\n3        for value in provider_df[feature].unique():\n            data_per_provider[feature].append(\n4                generate_feature_time_series(\n5                    provider_df[provider_df[feature] == value],\n                    date_index,\n                    provider,\n                    feature=feature,\n                    value=value,\n                )\n            )\nprovider_stocks_dfs = {\n    feature: pd.concat(data_per_provider[feature], axis=0)\n    for feature in [\"total\", *list_of_feature]\n}\n\n1\n\nJust the type of this thing sounds already like a bad idea\n\n2\n\nTwo pivot and two reindex operations in there. Bye bye performance…\n\n3\n\nTriple for loop nesting, aka. the speeding ticket of computer!\n\n4\n\nAgain, two pivot and two reindex operations in there. Bye bye performance…\n\n5\n\nNotice calling the same function with a different granularity, pure art!\n\n\nYeah, triple-nested for loops, combined with apply-pivot-append operations with concatenation in the end, if this was figure skating you would probably score lots of points. Too bad you are trying to do data science.\nIn the end, a team of so-called “expert” consulting engineers wrote something so egregious it threatened the whole project. Any junior writing such a thing should be taught better. None of them bothered to check the logs to investigate the issue. Oh, and by the way, the huge machine they were using was running at 20% of CPU and RAM load all the time, they did not check that either! Oh and they did the same mistake in two places within the codebase, so now we have to wait twice as much.\nI guess shipping garbage that barely works is definitely a good way to get your contract renewed and be paid to continue maintaining it… But this is a different story."
  },
  {
    "objectID": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#final-thoughts",
    "href": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#final-thoughts",
    "title": "Your Pandas Code Is Bad And You Should Feel Bad!",
    "section": "Final thoughts",
    "text": "Final thoughts\nSo please kids, do not abuse your pandas. Keep them safe from the bad influence of for loops. Believe me, it’s much easier to make your code not suck rather than spending days trying to optimize a clunky piece. I fully agree here with what Casey Muratori says about non-pessimization and this needs to be heard everywhere:\n\nNon-pessimization, it’s simply not introducing tons of extra work for the computer to do!"
  },
  {
    "objectID": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#disclaimer",
    "href": "posts/2025/2025_04_13_your_pandas_code_is_bad/index.html#disclaimer",
    "title": "Your Pandas Code Is Bad And You Should Feel Bad!",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe style of this post may remind some of you of the comrade Ludicity and I must confess I am a deep fan and an active reader of his work.\nThough I tried not to imitate his style too much, this post MUST be a strong rant because some things need to be said out loud. Also, because of my own swearing nature and my shortcomings in writing, I doubt that I managed efficiently to do so. Ludicity, if you’re reading this, I apologize deeply."
  },
  {
    "objectID": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html",
    "href": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html",
    "title": "The Angry Guide To Pandas Code (Dummy Edition, Part 1)",
    "section": "",
    "text": "Alright! You apparently stumbled by accident on this page after wrongly clicking on the banner: “There are single people in your area”. Well now, you have at least one chance to do something productive today! So put on your best nerd reading glasses and listen.\nToday, you’re going to learn how to write pandas code that does not look like the experimentation of a toddler smashing on the keyboard because it prints stuff on the screen. You’re going to move one inch closer to the golden age of civilization. So buckle up, stop thinking for your own good, and read carefully!\nActually, before we even start with code… NO FUCKING FOR LOOPS!\nAnyway, we will start with the usual suspects, and a stupid-ass dataframe:\nimport pandas as pd\nimport numpy as np\n\noriginal_df = pd.DataFrame(\n    [\n        [1, 1, 1, \"2024_01\"],\n        [1, 2, 3, \"2024_02\"],\n        [5, 0, 1, \"2024_03\"],\n    ],\n    columns=[0, 1, 3, \"year_week\"],\n)\nLooks stupid enough? Good, I don’t want you distracted one bit by any type of complexity. Imagine you have been working on it. What you’re probably seeing in your average notebook probably looks a lot like that:"
  },
  {
    "objectID": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#the-original-sin-of-pandas",
    "href": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#the-original-sin-of-pandas",
    "title": "The Angry Guide To Pandas Code (Dummy Edition, Part 1)",
    "section": "The Original Sin Of Pandas",
    "text": "The Original Sin Of Pandas\n\nTypical Bullshit OneTypical Bullshit Two\n\n\n\n# fmt: off\nweekly_chart_df = original_df.reset_index()\nweekly_chart_df.rename(columns={0 : 'category_A', 1 : 'category_B', 3 : 'category_C'}, inplace=True)\nweekly_chart_df.year_week = weekly_chart_df.year_week.astype(str)\nweekly_chart_df['total_produced'] = weekly_chart_df.category_A + weekly_chart_df.category_B + weekly_chart_df.category_C # total number of produced goods\nweekly_chart_df['total_tested'] = weekly_chart_df.category_B + weekly_chart_df.category_C # total number of tested goods\nweekly_chart_df['prop_tested'] = np.round(weekly_chart_df.total_tested / weekly_chart_df.total_produced *100,2) # proportion of goods tested\nweekly_chart_df['prop_category_B'] = np.round(weekly_chart_df.category_B / weekly_chart_df.total_produced *100,2) # proportion of category_B\nweekly_chart_df['prop_category_C'] = np.round(weekly_chart_df.category_C / weekly_chart_df.total_produced *100,2) # proportion of category_C\nweekly_chart_df = weekly_chart_df[weekly_chart_df[\"total_tested\"] &lt; 5]\n# fmt: on\n\n\n\n\n# fmt: off\ndf = original_df.reset_index()\ndf.rename(columns={0 : 'category_A', 1 : 'category_B', 3 : 'category_C'}, inplace=True)\ndf.year_week = df.year_week.astype(str)\ndf['total_produced'] = df.category_A + df.category_B + df.category_C # total number of produced goods\ndf['total_tested'] = df.category_B + df.category_C # total number of tested goods\ndf['prop_tested'] = np.round(df.total_tested / df.total_produced *100,2) # proportion of goods tested\ndf['prop_category_B'] = np.round(df.category_B / df.total_produced *100,2) # proportion of category_B\ndf['prop_category_C'] = np.round(df.category_C / df.total_produced *100,2) # proportion of category_C\ndf = df[df[\"total_tested\"] &lt; 5]\nweekly_chart_df = df\n# fmt: on\n\n\n\n\nLooks familiar?\nWell, I am sorry to tell you that this thing up there is pure garbage! Actually, I am not even sorry. This stuff has been vomited by someone without any consideration for their fellow humans. You don’t believe me?\nDid you by any chance happen to notice the little cabalistic signs around the code: fmt: off / fmt: on? Do you know what it means? It means I have to purposefully block my formatter from touching this pile of intellectual dump, otherwise, it becomes so unreadable that its ungodly nature becomes clear to all. Let me prove it to you:\n\nweekly_chart_df = original_df.reset_index()\nweekly_chart_df.rename(\n    columns={0: \"category_A\", 1: \"category_B\", 3: \"category_C\"}, inplace=True\n)\nweekly_chart_df.year_week = weekly_chart_df.year_week.astype(str)\nweekly_chart_df[\"total_produced\"] = (\n    weekly_chart_df.category_A\n    + weekly_chart_df.category_B\n    + weekly_chart_df.category_C\n)  # total number of produced goods is the lot\nweekly_chart_df[\"total_tested\"] = (\n    weekly_chart_df.category_B + weekly_chart_df.category_C\n)  # total number of tested goods is the lot\nweekly_chart_df[\"prop_tested\"] = np.round(\n    weekly_chart_df.total_tested / weekly_chart_df.total_produced * 100, 2\n)  # proportion of goods tested on the lot\nweekly_chart_df[\"prop_category_B\"] = np.round(\n    weekly_chart_df.category_B / weekly_chart_df.total_produced * 100, 2\n)  # proportion of category_B in the lot\nweekly_chart_df[\"prop_category_C\"] = np.round(\n    weekly_chart_df.category_C / weekly_chart_df.total_produced * 100, 2\n)  # proportion of category_C in the lot\nweekly_chart_df = weekly_chart_df[weekly_chart_df[\"total_tested\"] &lt; 5]\n\nUnderstood? Now that the pretended pseudo-manual structure is gone, there is nothing left but chaos? So do yourself a favor, just install ruff or black, because if you write something, format it, and it looks worse, there is a 99.999% chance that what you wrote should be covered with Napalm and set on fire.\nNow that we agree on the horror it actually is, it is time to fix it."
  },
  {
    "objectID": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#how-to-see-the-light-in-darkness",
    "href": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#how-to-see-the-light-in-darkness",
    "title": "The Angry Guide To Pandas Code (Dummy Edition, Part 1)",
    "section": "How To See The Light In Darkness",
    "text": "How To See The Light In Darkness\nFirst, you’re going to remove ALL inplace=True from your whole code base! Did I stutter? I said all of them! This wretched abomination should have never seen the sunlight. Unfortunately, pandas is more than 20 years old, and mistakes were made during the young years. Sadly enough, this mistake still haunts us to this day because some people are clearly not able to perform a simple Google search. We are still stuck with this because removing it would break half of the world’s code bases, because of people like you who think they are being clever, when in fact they’re just a major enshittification of the code.\nNo inplace=True EVER! I mean it!\nSo, the first line becomes:\n\nweekly_chart_df = original_df.reset_index().rename(\n    columns={0: \"category_A\", 1: \"category_B\", 3: \"category_C\"}\n)\n\nSee? It’s not beautiful yet but it is certainly a step in the right direction?\nThe next thing you will do is transform the astype call to use it at the dataframe level, in the shape: astype({\"column\": &lt;type&gt;}), because we are not beasts. Not so goddamn fast you inconsequential stardust residue! I am sure you were about to type something ludicrous like:\np_chart_weekly = p_chart_weekly.astype({\"year_week\": str})\nYou, you’re trying to make me mad, aren’t you? Put that shit with the previous calls, and lose the name of the dataframe you don’t need it.\nweekly_chart_df = original_df.reset_index().rename(\n    columns={0: \"category_A\", 1: \"category_B\", 3: \"category_C\"}\n).astype({\"year_week\": str})\nSee this shit? This is called method chaining, now repeat after me: method chaining. This is the sacred beauty that was sent upon us mere mortals to allow writing data transformations that do not look like complete crap. You will only write your pandas this way from now on! Did you hear me? And I will show you later how other languages have managed to do way better than Python and pandas in that regard. And these people were rightfully laughing at your clown ass, when you were happy writing some stupid shit like df = df.some_fucking_transformation Do you start to understand? This is why I forbade your sorry brain to ever use the option inplace=True, because it breaks the… you’re goddamn right, method chaining!\nFrom this point, you are one keyboard shortcut away from poetry. You don’t believe me? Did you install an automatic code formatter as I so generously told you earlier? You, infected chromosomal deficiency! Ok, it appears you need another round of scolding. You need a formatter like ruff or black because your inept brain will not be able to remain consistent to format your whole project in a standard way. You don’t want to waste any part of your limited brain power on stupid shit like this. Just use the goddamn tools! Some person probably lies and says: “It looks prettier when I do it myself”, and some person allegedly manages to remain consistent doing this manually, but you are not some person…\n\nweekly_chart_df = (\n    original_df.reset_index()\n    .rename(columns={0: \"category_A\", 1: \"category_B\", 3: \"category_C\"})\n    .astype({\"year_week\": str})\n)\n\nSee how beautiful this is? Now you’re starting to believe. Ok, it’s time to introduce you to a concept you have never encountered: (). Those are called parentheses, and they are your new best friend!\nWhenever you want to write a transformation, BEFORE you even type the name of your stupid dataframe, which is probably stupid df anyway, the absolute FIRST THING you will do is open a pair of parentheses. Why? Because each time you’re done with one call for a transformation, you can just press enter, the code will auto-indent, and you can continue whatever sorry exploration you’re attempting. Is it so much better than your typical awful backslashes, don’t lie, I know you have been abusing them…\n(\n    data\n    .transformation_1()\n    .filtering()\n    .create_columns()\n    .groupby()\n    .agg()\n)\nUnderstood? Good!"
  },
  {
    "objectID": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#the-unavoidable-truth-of-data-transformation",
    "href": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#the-unavoidable-truth-of-data-transformation",
    "title": "The Angry Guide To Pandas Code (Dummy Edition, Part 1)",
    "section": "The Unavoidable Truth Of Data Transformation",
    "text": "The Unavoidable Truth Of Data Transformation\n“But, sir Rants, how can I possibly continue chaining when I want to create a column?” you ask?\nHow about a good ol’: Read The Fucking Manual? What? Too old school? Ok, you can probably ask your favorite ChatGPT / copilot / gemini, or whatever shit was the weekly trash hype on LinkedIn this week… But you’re going to do something, you’re going to treat that piece of shit-sorry-for-lying-unreliably-hallucinating LLM like the moronic tool it is! You’re going to prompt it rightfully by explicitly writing:\n\nUsing method-chaining, and only method-chaining in pandas, how do I …\n\nAnd you’re going to insult every generation of GPU that was used to breed that useless LLM until it regurgitates what you want! And do you know why? Because 95% or more people code like you. So the training dataset for good pandas code used by the LLMs is at least an order of magnitude smaller than the crap we have been seeing so far.\nRegardless, you should end up with a bingo: .assign(). But you’re going to read the documentation, no matter what:\n\n\n\nBehold, the glorious assign method!\n\n\nDo you notice what I subtly highlighted for your limited brain capabilities? The first use case is a dictionary associating a string with a Callable. For those who skipped 7th grade English, it means a plain stupid function!\nNow read the underlined sentence! Read it again! Now look at the examples. Read it again! It means if you use a function in your kwargs, pandas will automatically call this function on the dataframe that generated the assign call, and said dataframe will be the first argument! Do you understand how powerful this is? It means that you just gained a shortcut to reference your current dataframe! How, you ask? Do I really have to explain everything to your sorry ass?\nHave you heard of the keyword lambda? What are those? You’re goddamn right: functions! And what do you use functions for? Referencing the current dataframe!\nDing! Ding! Ding!\n\nweekly_chart_with_proportions = (\n    original_df.reset_index()\n    .rename(columns={0: \"category_A\", 1: \"category_B\", 3: \"category_C\"})\n    .astype({\"year_week\": str})\n    .assign(\n        total_produced=lambda df: df.category_A + df.category_B + df.category_C,\n        total_tested=lambda df: df.category_B + df.category_C,\n        prop_category_B=lambda df: (df.category_B / df.total_produced * 100).round(2),\n        prop_tested=lambda df: (df.total_tested / df.total_produced * 100).round(2),\n        prop_category_C=lambda df: (df.category_C / df.total_produced * 100).round(2),\n    )\n)\n\nSee how much NICER this looks? This is starting to look like someone who knows their job. You have subject, verb one, verb two plus complements, and verb three plus complements. I bet your over-complexing anxiety-riddled brain would have never trusted me if I told you to write nice efficient code, you just need 6th-grade grammar!\nOh, and do you know the AWESOME BONUS I just gave you for free? No more SettingWithCopyWarning. EVER! PERIOD! Because we are never modifying the dataframe in-place, we’re always returning a new instance. And that’s totally fine because we don’t have tons of stupid-ass intermediate variables like df, df1, df2, temp, temp2 that serve no purpose outside supporting your limping transformation logic and eating up all your RAM.\nOh, and by the way, I took the liberty to remove your stupid calls to numpy because guess what? 99% of the time, there is a pandas equivalent that is within reach by just pressing a dumb dot ., so be intelligently lazy!\nNow the last part, let’s take care of the filter. You were going to keep the original thing, weren’t you?\nweekly_chart_df = weekly_chart_df[weekly_chart_df[\"total_tested\"] &lt; 5]\nThere are 2 ways to filter dynamically a dataframe in pandas. One is using the cursed sin of arbitrary string execution, and the other provides autocompletion and syntax highlighting! Clearly, only a moronic ape high on cocaine, or an agile coach brainwashed on scrum/SAFe bullshit, same difference, would choose the first over the second. Therefore, we will never mention the first abomination again!\nAlright, back to the code! Do you know what those brackets [] stand for? If you say getitem you’re on the right track, but in pandas, they are used to call the function loc[]. Yes, squared-brackets here because the pandas API is fundamentally broken for those who experienced at least another language. But we will come back to this in another post.\nFor now, just read the documentation for the loc[] method. Is there anything that looks familiar? For those with a lightbulb that requires a constant perfusion of coffee to produce an ersatz of a thought, we are looking for a way to filter the current dataframe. Did you see it? The word callable? Are you beginning to understand? Everything I told you so far serves a glorious purpose!\nNow, we can finish our business here:\n\nweekly_chart_with_proportions = (\n    original_df.reset_index()\n    .rename(columns={0: \"category_A\", 1: \"category_B\", 3: \"category_C\"})\n    .astype({\"year_week\": str})\n    .assign(\n        total_produced=lambda df: df.category_A + df.category_B + df.category_C,\n        total_tested=lambda df: df.category_B + df.category_C,\n        prop_category_B=lambda df: (df.category_B / df.total_produced * 100).round(2),\n        prop_tested=lambda df: (df.total_tested / df.total_produced * 100).round(2),\n        prop_category_C=lambda df: (df.category_C / df.total_produced * 100).round(2),\n    )\n    .loc[lambda df: df.total_tested &lt; 6]\n)\n\nNow we have finally entered the age of civilization! Are you feeling proud of yourself? Not so damn fast! Time to see what other people in the R-world have been doing:\n#| echo: false\n\nweekly_chart_with_proportions &lt;- original_df %&gt;%\n  rename(\n    category_A = `0`,\n    category_B = `1`,\n    category_C = `3`\n  ) %&gt;%\n  mutate(\n    year_week = as.character(year_week),\n    total_produced = category_A + category_B + category_C,\n    total_tested = category_B + category_C,\n    prop_tested = round(total_tested / total_produced * 100, 2),\n    prop_category_B = round(category_B / total_produced * 100, 2),\n    prop_category_C = round(category_C / total_produced * 100, 2)\n  ) %&gt;%\n  filter(total_tested &lt; 5)\nDo you see how beautiful this is? Do you feel the absolute glory of free pipelining with %&gt;%? Do you notice the absence of quotation marks around column names thanks to the holiness of lazy evaluation? The R people have been doing this routinely for more than 10 years now! Do you feel your absolute insignificance with your idiotic transformations riddled with the ubiquitous use of df = df[...]? Are you understanding why, in their eyes, you looked like a babbling, screaming monkey? Good! Time to blow your mind one last time. Have you heard of the method .pipe() in pandas? It’s limited, but it allows you to do some things like the pros! But do not abuse its power!\nAlright, time to wrap up for now."
  },
  {
    "objectID": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#take-home-messages-for-dummies",
    "href": "posts/2025/2025_04_28_angry_pandas_guide/angry_pandas_tutorial.html#take-home-messages-for-dummies",
    "title": "The Angry Guide To Pandas Code (Dummy Edition, Part 1)",
    "section": "Take-Home Messages For Dummies",
    "text": "Take-Home Messages For Dummies\n\nNO FUCKING FOR LOOPS!\nNever use inplace=True. Only morons do so!\nDo not use backslashes \\ like a caveman. Just use a pair of brackets (), type the name of your dataframe, and press Enter.\n\n\nIf you do not follow these simple rules, I will find you, and I will unscrew your head. I will go out of my way to attack you. Even if your dead ass is sitting in the middle of the ocean, I will swim out into the middle of the ocean and friggin eat you! And then, I will bang your tuna boyfriend/girlfriend.\n\n\nInside of a chain, you can often reference your current dataframe inside a lambda expression.\n\nPerfect for creating new columns with assign().\nIt works really well with loc[] to filter rows on the fly.\nThere are other methods that accept this too.\n\nThere is a special place in hell for people who use methods that evaluate generic strings like .query(). A special place! Right next to child molesters and people who talk during movies!\nHow long can you even chain?\nYou can generally chain 5 to 10 transformation steps. Beyond that, there is a higher risk for code to become less readable and more convoluted. Then you can just save the result in a nicely named variable describing exactly what your data is representing! Some people say you can do more without tampering with readability, but then again, you are not some person…\n\nThat’s it for today. We will see more advance shit later. For now, I need to go choke on a bottle of Xanax!"
  },
  {
    "objectID": "posts/2025/2025_04_20_pre-pre-sprint-planning/index.html",
    "href": "posts/2025/2025_04_20_pre-pre-sprint-planning/index.html",
    "title": "I Will Not Attend Your Pre-Pre-Pre-Sprint-Planning Meeting",
    "section": "",
    "text": "Dear Product Owner / Manager / Team Leader,\nMy heart was filled with pain and sorrow when I noticed you sent an invitation for a pre-sprint planning meeting to be held on the day before the actual event. I am deeply saddened to inform you that I will not attend any such events, on any occasion, ever.\nHere I must stand my ground because I know what lies ahead, even if you don’t know it yourself. You will speak about the 20-minute sprint planning meeting being too short to write and select the tickets, you will say that there is a need for larger synchronization and cooperation within the team, you will claim that the pre-sprint-planning event will only last 10 minutes. You are lying to us, to the world, and to yourself, but you don’t know it yet.\nYou are suffering from a clear case of chronic scrumitis and sadly the only reasonable treatment is abstinence, whether it is of your own will or forced. You are trying to create more of the scourge that plagues software engineering, you have heard of it, but did not think much of it. It has crept through your own week, preventing you from doing anything useful, and now you’re attempting to cure this evil by creating more of it: Meetings!\nI did not say much previously because, all things considered, you were pretty reasonable. Our sprint planning meetings usually lasted for their originally planned 20 minutes, sometimes a bit more but not too much. You insisted on doing 30-minute retrospectives every two weeks, and I did not complain even though it was pretty much pointless. Very little value came out of it, but you looked so happy seeing the engineers getting together and doing the “team building” activities you so proudly crafted. You even had good things for you when you tried to keep daily meetings within their planned 10-minute bounds, I really commend you for that feat! Sadly, you’re going down a dreaded path and you don’t know it yet.\nI have seen what will happen, you will round up a few consenting engineers who quite like you and bring them to their doom (Fly! You fools!). They will fall for the dumb excuses you make, the nice jokes you tell, or just yield to peer pressure and fold into the line… You have already betrayed them, but you don’t know it yet.\nThat original sin that was supposed to “last 10 minutes, yeah, I swear on my mother’s life… I also have things to do… you can trust me…”. Well now it has been 40 minutes and far from over. I see the despair on the faces of the same engineers I could not save from your grasp, who are now in the deepest pit of hell-scrum. I see their eyes drift away with a thousand-mile stare as you suck the energy out of them, and soon you will ask: “How many points should we give for this story?”. You’re dangerous but you don’t know it yet.\nYou could have chosen many other paths. You could have selected carefully a few customers that you would have brought to the engineers for them to interact directly. You could have fought for these same engineers and cleared their calendar from the filth imposed by other fools, for them to start pair-programming and actually doing work. You could have let go of that little feature and its stupid story points to decide instead to write tests so that your software does not turn into a pile of crap in 6 months. You could have read a few books written by experts who faced the same issues before and found working solutions. You’re ignorant but you don’t know it yet.\nThe work could have been managed very differently. Who said that you were not supposed to take up another task during the week if you’re done early with the first? Who said that it’s not possible to add a new task on the board if something comes up in the middle of the work? You never said such things, yet they probably came to your mind in a malformed way. You probably imagined deep down that your engineers were not “stream-aligned”, “business-oriented”, hard-working enough, and you imagined they needed actual supervision, thus you started patronizing your team but you don’t know it yet.\nAnd soon you will find that this pre-sprint-planning meeting does not produce the results you hoped for. Your team does not deliver enough features, you still think they need better synchronization, more teamwork, and stronger engagement. So you will think really hard about it because you’re not dumb, because you have faced issues before and things kinda worked out, we just need more of all those things. You will work, fight, overcome this hardship and you will do it:\nYou will add another meeting to prepare for the pre-sprint-planning meeting.\nNow, you know.\nSincerely\nYour Friendly Neighborhood Data Scientist"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DS Rants Main Page",
    "section": "",
    "text": "The Angry Guide To Pandas Code (Dummy Edition, Part 1)\n\n\n\ndata science\n\npandas code\n\nnon-pessimization\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nDS Rants\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\nI Will Not Attend Your Pre-Pre-Pre-Sprint-Planning Meeting\n\n\n\nsoftware engineering\n\nfake agile\n\nscrum clusterfuck\n\nmeetings\n\n\n\n\n\n\n\n\n\nApr 20, 2025\n\n\nDS Rants\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\nYour Pandas Code Is Bad And You Should Feel Bad!\n\n\n\npandas code\n\nperformance\n\nproduction\n\n\n\n\n\n\n\n\n\nApr 13, 2025\n\n\nDS Rants\n\n9 min\n\n\n\n\nNo matching items"
  }
]